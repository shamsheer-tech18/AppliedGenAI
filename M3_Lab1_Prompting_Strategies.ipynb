{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shamsheer-tech18/AppliedGenAI/blob/main/M3_Lab1_Prompting_Strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Intro Section -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 30px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 32px;\">Introduction to Prompting Strategies</h1>\n",
        "    <p style=\"font-size: 18px; margin: 0;\">Instructor: <strong>Dr. Dehghani</strong></p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Why It Matters Section -->\n",
        "<div style=\"background: #ffffff; padding: 25px; border-radius: 10px; border-left: 6px solid #0055d4; box-shadow: 0 4px 8px rgba(0,0,0,0.05);\">\n",
        "    <h2 style=\"margin-top: 0; color: #001a70;\">Why Prompting Strategies Matter</h2>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Imagine you‚Äôre working with a junior engineer. You say:  \n",
        "        <em>‚ÄúOptimize the system.‚Äù</em><br>\n",
        "        They‚Äôll probably ask: <em>‚ÄúWhich system? Optimize for cost, speed, or energy? Any constraints?‚Äù</em> üßê\n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Now try this instead:  \n",
        "        <em>‚ÄúAnalyze the HVAC system and minimize energy consumption while keeping temperatures between 22-24¬∞C. Provide a cost breakdown.‚Äù</em>  \n",
        "    </p>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        That‚Äôs not just a prompt‚Äîit‚Äôs a <strong>clear strategy</strong> with defined objectives and boundaries.\n",
        "        And that‚Äôs exactly what AI models need to perform at their best.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Tip Section -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 30px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Pro Tip</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        AI models appreciate well-structured instructions just like engineers appreciate complete design specs.\n",
        "        Be specific, set clear goals, and watch the results improve!\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Upcoming Topics -->\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">What‚Äôs Ahead</h3>\n",
        "    <ul style=\"list-style: none; padding: 0; font-size: 16px; line-height: 1.8;\">\n",
        "        <li>üìö Basic Prompting Types</li>\n",
        "        <li>üß© Advanced Strategies</li>\n",
        "        <li>üìä Application-Specific Techniques</li>\n",
        "    </ul>\n",
        "    <p style=\"font-size: 16px; color: #333;\">Let‚Äôs engineer some powerful AI conversations! üõ†Ô∏è</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "VuSW9V7pZvnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Section Header -->\n",
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "    <h1 style=\"margin-bottom: 10px; font-size: 30px;\">üìö Basic Prompting Types</h1>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 25px;\"></div>\n",
        "\n",
        "<!-- Zero-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">1Ô∏è‚É£ Zero-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide only the task without any examples.  \n",
        "        <strong>Use When:</strong> The task is simple and well-known by the model.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "cjZ5fTTNbfyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Set Up LLM and OpenAI API\n",
        "# ==========================\n",
        "# Import required libraries\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Load the OpenAI API key securely from Colab secrets\n",
        "api_key = userdata.get('OpenAI_API_Key')\n",
        "\n",
        "# Check that the API key was found\n",
        "if api_key is None:\n",
        "    raise ValueError(\"‚ùå API Key not found. Please store your OpenAI API key using Colab secrets.\")\n",
        "\n",
        "# Set API key as environment variable for OpenAI\n",
        "os.environ[\"OpenAI_API_Key\"] = api_key\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "print(\"‚úÖ OpenAI API Key successfully loaded and environment is ready!\")\n",
        "\n",
        "# ==========================\n",
        "# üìå Set LLM Model to GPT-3.5\n",
        "# ==========================\n",
        "# Define which LLM model to use\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "print(f\"‚úÖ LLM model set to: {model_name}\")\n"
      ],
      "metadata": {
        "id": "dB3jBmICZwED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d811b711-40fb-446d-f76a-dc63a4a3df21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API Key successfully loaded and environment is ready!\n",
            "‚úÖ LLM model set to: gpt-3.5-turbo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATION:**\n",
        "In this task, provided the api_key for the model, and asked to check if the key is found with the provided info key. Since it found, it has responded by printing the value as ‚ÄúOpenAI API Key successfully loaded and environment is ready!‚Äù and the LLM model was set to ‚Äúgpt-3.5-turbo‚Äù"
      ],
      "metadata": {
        "id": "LMmsoQQxKeiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot Test: Hidden Formula Sequence\n",
        "# ==========================\n",
        "\n",
        "hard_sequence_prompt_zero = (\n",
        "    \"The sequence is: 3, 12, 27, 48, 75, ___. What‚Äôs next?\"\n",
        ")\n",
        "\n",
        "response_zero_hard = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": hard_sequence_prompt_zero}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(\"üîπ LLM Response (Zero-Shot - Hard Sequence):\\n\")\n",
        "print(response_zero_hard.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AO4UhSJxb0Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c0d57a-288a-48da-aefd-73c77eb4068a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ LLM Response (Zero-Shot - Hard Sequence):\n",
            "\n",
            "The pattern in the sequence is adding consecutive odd numbers to the previous number. \n",
            "\n",
            "3 + 9 = 12\n",
            "12 + 15 = 27\n",
            "27 + 21 = 48\n",
            "48 + 27 = 75\n",
            "\n",
            "Therefore, the next number in the sequence would be 75 + 33 = 108. \n",
            "\n",
            "So, the next number in the sequence is 108.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATIONS:**\n",
        "In this test, asked the model to find the hidden formula in the sequence numbers without providing any example to the model. The model responded by correctly identifying the pattern and predicted the next number as 108. This response was captured by setting the temperature value as ‚Äú0‚Äù."
      ],
      "metadata": {
        "id": "ZOBAGp72KnI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- One-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">2Ô∏è‚É£ One-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide one clear example along with the instruction.  \n",
        "        <strong>Use When:</strong> You want to guide the model‚Äôs behavior with a single example.  \n",
        "        <em>Example:</em> ‚ÄúTranslate 'Hello' to French: Bonjour. Now translate 'Goodbye'.‚Äù\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "zN2CjeJunlV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Zero-Shot vs One-Shot Comparison: Alternating Pattern Sequence (Correct One-Shot)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Example)\n",
        "zero_shot_prompt = (\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# One-Shot Prompt (One Example + New Question)\n",
        "one_shot_prompt = (\n",
        "    \"Example:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Now solve this one:\\n\"\n",
        "    \"The sequence is: 1, 4, 2, 9, 3, 16, 4, ___. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run One-Shot\n",
        "response_one = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": one_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\n\\nüîπ One-Shot Response:\\n\" + \"-\"*40)\n",
        "print(response_one.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "AWI0m9_eciJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f914761f-8608-4f5e-fd30-6bd1dcec54b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response:\n",
            "----------------------------------------\n",
            "The pattern is: \n",
            "\n",
            "1^2 = 1\n",
            "2^2 = 4\n",
            "3^2 = 9\n",
            "4^2 = 16\n",
            "\n",
            "Therefore, the next number in the sequence should be 5^2 = 25. \n",
            "\n",
            "So, the number that should replace the blank is 25.\n",
            "\n",
            "\n",
            "üîπ One-Shot Response:\n",
            "----------------------------------------\n",
            "Answer: 25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATIONS:**\n",
        "Used ‚Äúgpt-3.5-turbo‚Äù model\n",
        "In this example, compared the Zero-shot and one-shot prompting, where in zero-shot asked the model to find the number in the sequence without giving any example, and in one-shot prompting asked model to find the number in the sequence by providing the examples to the model. In response, zero-shot provided the detailed explanation of why the next number is picked as 25, but in one-shot it gave the output value directly without explaining by referring the provided examples.\n"
      ],
      "metadata": {
        "id": "L-ZrZCyAKt4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<!-- Few-Shot Prompting -->\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #001a70;\">3Ô∏è‚É£ Few-Shot Prompting</h3>\n",
        "    <p style=\"font-size: 16px; line-height: 1.6;\">\n",
        "        Provide multiple examples to clearly demonstrate the pattern.  \n",
        "        <strong>Use When:</strong> The task is complex or requires understanding a specific format.  \n",
        "        <em>Example:</em>  \n",
        "        - ‚ÄúTranslate 'Hello' to French: Bonjour.‚Äù  \n",
        "        - ‚ÄúTranslate 'Goodbye' to French: Au revoir.‚Äù  \n",
        "        - ‚ÄúTranslate 'Thank you' to French: Merci.‚Äù  \n",
        "        Now translate 'Good night'.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<!-- Spacer -->\n",
        "<div style=\"height: 30px;\"></div>\n",
        "\n",
        "<!-- Closing Tip -->\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <h3 style=\"margin-top: 0; color: #0055d4;\">üí° Quick Reminder</h3>\n",
        "    <p style=\"margin: 0; font-size: 16px; line-height: 1.6;\">\n",
        "        The more complex the task, the more examples you should provide. But remember, too many examples can make prompts bulky and inefficient.\n",
        "    </p>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "DdXDGKuAnawA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Few-Shot Prompting Example: Ultra-Hard Pattern (3 Hidden Rules)\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Best for complex reasoning\n",
        "\n",
        "# Few-Shot Prompt with 2 Examples\n",
        "few_shot_prompt = (\n",
        "    \"Example 1:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 3, 9, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 4.\\n\\n\"\n",
        "    \"Example 2:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, ___. What‚Äôs next?\\n\"\n",
        "    \"Answer: 11.\\n\\n\"\n",
        "    \"Now try this one:\\n\"\n",
        "    \"The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36. What number should replace the blank?\"\n",
        ")\n",
        "\n",
        "# Run Few-Shot Prompt\n",
        "response_few = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": few_shot_prompt}],\n",
        "    temperature=0.5\n",
        ")\n",
        "\n",
        "# Display Result\n",
        "print(\"üîπ Few-Shot Prompting (Two Examples Provided):\")\n",
        "print(\"-\" * 40)\n",
        "print(response_few.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "3FLfQaF8mwB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c715a6ff-7da9-4cb3-ac3f-8cca66917100"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Few-Shot Prompting (Two Examples Provided):\n",
            "----------------------------------------\n",
            "To solve this sequence, let's analyze the given numbers and see if we can identify a pattern or rule:\n",
            "\n",
            "The sequence is: 1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36.\n",
            "\n",
            "Let's look at each number and see if there's a relationship between them:\n",
            "\n",
            "1. The first few numbers don't provide a clear pattern, so let's look at the later numbers:\n",
            "   - 4 (squared) = 16\n",
            "   - 9 (squared) = 81, but we see 9 and then 7, which doesn't directly relate.\n",
            "   - 4 (squared) = 16 (again)\n",
            "   - 16 (squared) = 256, but we see 16 and then 36 (which is 6 squared).\n",
            "\n",
            "2. We can observe that every few numbers, the sequence involves squares:\n",
            "   - 4, 4, 9, 7, 16, 11, ___, 16, 36\n",
            "   - Squares observed: 4, 9, 16, 36 (4^2, 3^2, 4^2, 6^2)\n",
            "\n",
            "3. Let's see if there's a pattern in the numbers immediately before the squares:\n",
            "   - Before 4 (which is 2^2), there is 2.\n",
            "   - Before 9 (which is 3^2), there is 4.\n",
            "   - Before 16 (which is 4^2), there is 7.\n",
            "   - Before 36 (which is 6^2), there should be 11 (as 5^2 = 25 doesn't fit, but we see a pattern of increasing odd numbers: 4, 7, 11).\n",
            "\n",
            "4. The pattern between the non-square numbers seems to be increasing by 3, then by 4:\n",
            "   - 2 to 4 (increase by 2)\n",
            "   - 4 to 7 (increase by 3)\n",
            "   - 7 to 11 (increase by 4)\n",
            "\n",
            "5. Following this pattern, after 11, the next increase should be by 5:\n",
            "   - 11 + 5 = 16\n",
            "\n",
            "Thus, the number that should replace the blank in the sequence 1, 1, 2, 4, 4, 9, 7, 16, 11, ___, 16, 36 is 16.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATIONS:**\n",
        "Since we are solving a complex reasoning problem, used ‚Äúgpt-4-turbo‚Äù model for solving it better.\n",
        "In this example, provided 2 different examples of the reasoning problems and asked model to find a number in a sequence, and temperature was set to ‚Äú0.5‚Äù to make the model respond accordingly. In response the model has defined the missing number as 16 and given the clear steps of identifying the missing number in the sequence. This is done as per the given examples to the model and to its reasoning ability."
      ],
      "metadata": {
        "id": "rMfo6ib7Kz3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m0ICbL-NnaGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Advanced Prompting Techniques  \n",
        "\n",
        "Moving beyond basic prompting methods like zero-shot and few-shot, advanced strategies help enhance the reasoning and adaptability of large language models (LLMs). These techniques guide the model's thought process to handle complex tasks more effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### üîó Chain-of-Thought (CoT) Prompting  \n",
        "\n",
        "Chain-of-Thought prompting encourages models to **explain their intermediate reasoning steps**, leading to more transparent and accurate conclusions. By structuring prompts to include logical steps, CoT improves the model‚Äôs ability to solve complex reasoning tasks.\n",
        "\n",
        "**Why is CoT Important?**  \n",
        "- ‚úîÔ∏è Improves performance on multi-step reasoning tasks.  \n",
        "- ‚úîÔ∏è Helps produce logically structured and coherent responses.  \n",
        "- ‚úîÔ∏è Breaks down complex problems into manageable steps.\n",
        "\n",
        "üìñ **Reference:** [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, explore practical examples of Chain-of-Thought prompting.*\n"
      ],
      "metadata": {
        "id": "cJYU0rOaTD5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Chain-of-Thought Demonstration: Make 110 with Five 5's\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly five 5‚Äôs and only four operations (+, -, *, /) and parentheses to make 110.\\n\"\n",
        "    \"Step 1: Assume we cannot combine the 5's to form larger numbers (e.g., 55).\\n\"\n",
        "    \"Step 2: Try to combine them logically to reach 110.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\nüîπ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "id": "rNdqf6qGnJY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ef930d-19ce-4bff-c0d4-e0600c46582b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To achieve the number 110 using exactly five 5's and the operations (+, -, *, /) along with parentheses, you can arrange them as follows:\n",
            "\n",
            "\\[ 5 * (5 + 5) + 55 = 110 \\]\n",
            "\n",
            "Here's the breakdown:\n",
            "1. \\(5 + 5 = 10\\)\n",
            "2. \\(5 * 10 = 50\\)\n",
            "3. \\(50 + 55 = 110\\)\n",
            "\n",
            "This expression uses exactly five 5's and the operations as specified.\n",
            "\n",
            "üîπ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To solve this, we need to find a way to use exactly five 5's and the allowed operations to reach 110. Here's a step-by-step approach to find the solution:\n",
            "\n",
            "Step 1: Start by considering the basic operations and how they can combine to reach a target close to 110 using five 5's.\n",
            "\n",
            "Step 2: Experiment with different combinations of operations and groupings (parentheses) to manipulate the values effectively.\n",
            "\n",
            "After trying different combinations, one possible solution is:\n",
            "\\[ (5 + 5) \\times (5 + 5) + \\frac{5}{5} = 110 \\]\n",
            "\n",
            "Explanation:\n",
            "1. \\( (5 + 5) = 10 \\)\n",
            "2. \\( (5 + 5) = 10 \\)\n",
            "3. \\( 10 \\times 10 = 100 \\)\n",
            "4. \\( \\frac{5}{5} = 1 \\)\n",
            "5. \\( 100 + 1 = 101 \\)\n",
            "\n",
            "This solution uses exactly five 5's and four operations, reaching the target of 110.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úã Hands-On Experiment: Observations  \n",
        "\n",
        "üìå **Instructions:**  \n",
        "- Run your experiments by changing the model type (e.g., `gpt-3.5-turbo`, `gpt-4-turbo`, `gpt-o3`), temperature, and prompt style.  \n",
        "- You can **either attach a screenshot/image of your results** or **write a brief summary of your observations (max half a page)**.\n",
        "\n",
        "---\n",
        "\n",
        "- **Model Used:**  \n",
        "  _[Enter the model name you tried, e.g., gpt-3.5-turbo, gpt-4-turbo, or gpt-o3]_\n",
        "\n",
        "- **Temperature Setting:**  \n",
        "  _[Enter the temperature you used, e.g., 0.0, 0.5, 0.7]_\n",
        "\n",
        "- **Zero-Shot Result:**  \n",
        "  _[Did Zero-Shot solve the problem correctly? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Chain-of-Thought Result:**  \n",
        "  _[Did Chain-of-Thought solve the problem better? Yes/No. Add a short explanation or attach an image.]_\n",
        "\n",
        "- **Key Takeaways (Max Half Page or Screenshot):**  \n",
        "  _[Summarize what you observed. Did a specific model perform better? How did temperature affect the results? What worked best? Attach image or write here.]_\n",
        "\n",
        "---\n",
        "\n",
        "‚úçÔ∏è *Try at least two models and different temperatures. Compare the results and reflect on how prompting strategies influence performance!*\n"
      ],
      "metadata": {
        "id": "LQ6og568laaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# üß™ Chain-of-Thought Demonstration: Make 24 with Four 3's\n",
        "# ===========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"\n",
        "\n",
        "# Zero-Shot Prompt (No Reasoning Encouraged)\n",
        "zero_shot_prompt = (\n",
        "    \"Use exactly four 3's and only four operations (+, -, *, /) and parentheses to make 24.\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Encourages Step-by-Step Reasoning)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    \"We need to use exactly four 3's and only four operations (+, -, *, /) and parentheses to make 24.\\n\"\n",
        "    \"Step 1: Assume we cannot combine the 3's to form larger numbers (e.g., 33).\\n\"\n",
        "    \"Step 2: Think about what operations on 3's can give us factors of 24.\\n\"\n",
        "    \"Step 3: Try to combine them logically to reach 24.\\n\"\n",
        "    \"Now, provide the final equation and the answer.\"\n",
        ")\n",
        "\n",
        "# Run Zero-Shot\n",
        "response_zero = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": zero_shot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Run Chain-of-Thought\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Display Results\n",
        "print(\"‚óÜ Zero-Shot Response (No Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_zero.choices[0].message.content.strip())\n",
        "\n",
        "print(\"\\n‚óÜ Chain-of-Thought Response (Reasoning Encouraged):\\n\" + \"-\" * 50)\n",
        "print(response_cot.choices[0].message.content.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMAPAi2-JQOX",
        "outputId": "60f87070-bc4b-4fc0-eb28-4132bb22aac9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚óÜ Zero-Shot Response (No Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "One way to use exactly four 3's and the operations (+, -, *, /) along with parentheses to make 24 is as follows:\n",
            "\n",
            "\\[ (3 \\times 3 + 3) \\times 3 = 24 \\]\n",
            "\n",
            "Here's the breakdown:\n",
            "1. Multiply the first two 3's: \\(3 \\times 3 = 9\\)\n",
            "2. Add the third 3 to the result: \\(9 + 3 = 12\\)\n",
            "3. Multiply the result by the fourth 3: \\(12 \\times 3 = 24\\)\n",
            "\n",
            "‚óÜ Chain-of-Thought Response (Reasoning Encouraged):\n",
            "--------------------------------------------------\n",
            "To solve this, let's follow the steps you outlined and find a way to use four 3's and the operations (+, -, *, /) to make 24.\n",
            "\n",
            "Step 1: We cannot combine the 3's to form larger numbers like 33.\n",
            "\n",
            "Step 2: Consider operations that can give us factors or results that lead to 24. We know that:\n",
            "- Multiplying 3 by 8 gives 24, but we need to see how to make 8 using three 3's.\n",
            "- Adding 3 + 3 + 3 + 3 gives 12, which is half of 24.\n",
            "- Dividing 3 by 3 gives 1, which might not seem immediately helpful.\n",
            "\n",
            "Step 3: Combine them logically:\n",
            "- We can use multiplication, division, and addition in various ways. One effective method is to consider how to use division or subtraction to adjust the scale of the numbers.\n",
            "\n",
            "Here's a solution:\n",
            "- We can use the factorial of 3, which is 6, but since we're limited to basic operations, let's find another way.\n",
            "- Consider using parentheses to control the order of operations and possibly division to adjust the scale.\n",
            "\n",
            "One possible equation is:\n",
            "\\[ (3 \\times 3 \\times 3 - 3) = 24 \\]\n",
            "Explanation:\n",
            "- First, multiply three 3's: \\(3 \\times 3 \\times 3 = 27\\).\n",
            "- Then subtract the remaining 3: \\(27 - 3 = 24\\).\n",
            "\n",
            "Thus, the final equation using exactly four 3's and basic operations to make 24 is:\n",
            "\\[ (3 \\times 3 \\times 3 - 3) = 24 \\]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATIONS:**\n",
        "This compares the Zero-shot and CoT prompting to make the 24 using teh four 3's. It is observed that zero-shot gives teh resposne wiothout any explanation, but CoT has given the step guidanves for reasoning and produced a clear and logical solution. Used the \"gpt-4-turbo\" model for performing the reasoning.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nt879fEPJrRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÅ Self-Consistency Prompting\n",
        "\n",
        "While Chain-of-Thought (CoT) improves reasoning by encouraging step-by-step thinking, it may still produce **inconsistent or incorrect** answers, especially in complex scenarios.  \n",
        "**Self-Consistency Prompting** enhances CoT by asking the model to **generate multiple reasoning paths** and then select the most common or consistent final answer.\n",
        "\n",
        "### Why is Self-Consistency Useful?\n",
        "\n",
        "- ‚úÖ Reduces random reasoning errors.\n",
        "- ‚úÖ Boosts reliability on ambiguous or multi-path problems.\n",
        "- ‚úÖ Often improves performance on mathematical, logical, and symbolic tasks.\n",
        "\n",
        "üìñ **Reference**: [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)\n",
        "\n",
        "---\n",
        "\n",
        "*Next, we‚Äôll see how Self-Consistency works in action using a complex reasoning example.*\n"
      ],
      "metadata": {
        "id": "RN2Af6nAkKi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# üìå Comparing Chain-of-Thought vs. Self-Consistency Prompting\n",
        "# ==========================\n",
        "\n",
        "model_name = \"gpt-4-turbo\"  # Using GPT-4 for better reasoning\n",
        "\n",
        "# Define the problem prompt\n",
        "problem_prompt = (\n",
        "    \"If a train travels at 60 miles per hour and leaves at 2 PM, and another train leaves \"\n",
        "    \"the same station at 3 PM traveling at 90 miles per hour, when will the second train catch up to the first?\"\n",
        ")\n",
        "\n",
        "# Chain-of-Thought Prompt (Standard)\n",
        "cot_prompt = (\n",
        "    \"Let's solve this step by step.\\n\"\n",
        "    + problem_prompt\n",
        ")\n",
        "\n",
        "# Self-Consistency Prompt: Ask the model to produce multiple reasoning paths\n",
        "def run_self_consistency(prompt, num_attempts=5):\n",
        "    answers = []\n",
        "    for _ in range(num_attempts):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7  # Add randomness to explore different reasoning paths\n",
        "        )\n",
        "        answer = response.choices[0].message.content.strip()\n",
        "        answers.append(answer)\n",
        "    return answers\n",
        "\n",
        "# Run Chain-of-Thought (Single Attempt)\n",
        "response_cot = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[{\"role\": \"user\", \"content\": cot_prompt}],\n",
        "    temperature=0\n",
        ")\n",
        "cot_answer = response_cot.choices[0].message.content.strip()\n",
        "\n",
        "# Run Self-Consistency (Multiple Attempts)\n",
        "sc_answers = run_self_consistency(cot_prompt, num_attempts=5)\n",
        "\n",
        "# Simple Majority Vote to Find Most Consistent Answer\n",
        "from collections import Counter\n",
        "most_common_answer = Counter(sc_answers).most_common(1)[0]\n",
        "\n",
        "# Display Results\n",
        "print(\"üîπ Chain-of-Thought Response (Single Attempt):\\n\" + \"-\" * 50)\n",
        "print(cot_answer)\n",
        "\n",
        "print(\"\\nüîπ Self-Consistency Responses (Multiple Attempts):\\n\" + \"-\" * 50)\n",
        "for idx, ans in enumerate(sc_answers, 1):\n",
        "    print(f\"Attempt {idx}: {ans}\")\n",
        "\n",
        "print(\"\\nüîπ Final Self-Consistency Selected Answer:\\n\" + \"-\" * 50)\n",
        "print(f\"Most Common Answer: {most_common_answer[0]}\\nAppeared {most_common_answer[1]} times.\")\n"
      ],
      "metadata": {
        "id": "yNWwXIahdaOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìö Exploring More Advanced Prompting Strategies</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>üß© Tree-of-Thought (ToT) Prompting:</strong> Explores multiple reasoning paths like a decision tree, helping the model evaluate and compare various solutions before choosing the best one.</li>\n",
        "        <li><strong>ü§ñ ReAct (Reasoning and Acting) Prompting:</strong> Combines reasoning steps with actions, including API calls or external tool usage. Ideal for interactive agents and dynamic decision-making tasks.</li>\n",
        "        <li><strong>üîÑ Reflexion Prompting:</strong> Encourages the model to critique its own responses and iteratively improve them, simulating self-correction and learning.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">‚úã Hands-On Task: Compare Prompting Strategies</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        üìå <strong>Task Instructions:</strong><br>\n",
        "        - Experiment with <strong>Self-Consistency</strong>, <strong>Tree-of-Thought</strong>, and <strong>ReAct</strong> prompting methods.<br>\n",
        "        - Try to solve the following problem using each method and compare the results.\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <h3>üß† <strong>Challenge Problem:</strong></h3>\n",
        "    <p style=\"font-size: 16px;\">A farmer has chickens and rabbits in a cage. There are 35 heads and 94 legs. How many chickens and rabbits are there?</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Try different models (e.g., <code>gpt-3.5-turbo</code>, <code>gpt-4-turbo</code>, <code>gpt-o3</code>).</li>\n",
        "        <li>Experiment with different temperatures (e.g., <code>0.0</code>, <code>0.5</code>, <code>0.7</code>).</li>\n",
        "        <li>Use both direct prompts and advanced strategies like CoT, Self-Consistency, or ReAct.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h2 style=\"color: #001a70;\">üìñ Observations</h2>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li><strong>Model and Strategy Used:</strong><br>_[Enter the model and prompting strategy you tried]_</li>\n",
        "        <li><strong>Was the Correct Answer Found?</strong><br>_[Yes/No. Explain briefly or attach a screenshot]_</li>\n",
        "        <li><strong>Key Takeaways (Max Half Page or Screenshot):</strong><br>_[Summarize how different strategies performed. What worked best? Why?]_</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 20px; text-align: center;\">\n",
        "    ‚úçÔ∏è <em>Hint: Try breaking down the problem into equations or ask the model to explain its steps before giving the final answer. Notice which strategies lead to faster and more accurate results!</em>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Hfw5kDf5l_o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# ‚úã Hands-On Code: Try Different Prompting Strategies and Models\n",
        "# ==========================\n",
        "\n",
        "# üìù Instructions:\n",
        "# - Change 'model_name' to try different models (e.g., \"gpt-3.5-turbo\", \"gpt-4-turbo\", \"gpt-o3\").\n",
        "# - Adjust 'temperature' to test how creativity affects reasoning.\n",
        "# - Try Self-Consistency by sampling multiple outputs and comparing answers.\n",
        "# - Optionally, explore Tree-of-Thought and ReAct patterns by modifying prompts.\n",
        "# ‚úÖ Your Experiment Starts Here üëá\n"
      ],
      "metadata": {
        "id": "5kYqO4FgkJd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background: linear-gradient(135deg, #001a70 0%, #0055d4 100%); color: white; padding: 25px; border-radius: 12px; text-align: center;\">\n",
        "    <h1 style=\"margin-bottom: 10px;\">üìå Conclusion</h1>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        In this hands-on exploration, different advanced prompting strategies were tested to solve reasoning-based challenges.\n",
        "        Through experimenting with <strong>Chain-of-Thought (CoT)</strong>, <strong>Self-Consistency</strong>, and other methods,\n",
        "        the following key insights were observed:\n",
        "    </p>\n",
        "    <ul style=\"font-size: 16px; line-height: 1.8;\">\n",
        "        <li>Advanced prompting techniques significantly improve model performance, especially on complex, multi-step problems.</li>\n",
        "        <li>Changing the <strong>model type</strong> and <strong>temperature</strong> can drastically affect reasoning quality and creativity.</li>\n",
        "        <li>Some strategies, like <strong>Self-Consistency</strong>, help reduce random errors by exploring multiple reasoning paths.</li>\n",
        "        <li>For ambiguous or challenging problems, combining strategies (e.g., CoT + Self-Consistency) often leads to the most reliable results.</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #f5faff; padding: 20px; border-radius: 8px; border-left: 5px solid #0055d4; margin-top: 20px;\">\n",
        "    <p style=\"font-size: 16px; font-style: italic;\">\n",
        "        üìñ <em>Remember: Prompt engineering is both an art and a science. The more you experiment, the better you understand how to guide LLMs effectively!</em>\n",
        "    </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"margin-top: 40px; text-align: center;\">\n",
        "    <h3 style=\"color: #001a70;\">‚úçÔ∏è Final Reflection</h3>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: #ffffff; padding: 20px; border-radius: 10px; border-left: 6px solid #0055d4;\">\n",
        "    <p style=\"font-size: 16px;\">\n",
        "        _[Write 2-3 sentences summarizing what you personally learned about prompting strategies and how model selection or temperature influenced the results.]_\n",
        "    </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "sivjpWXsmlUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2WJRwTsOmlrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}